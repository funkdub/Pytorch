{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Test_Feng.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/funkdub/Pytorch/blob/master/LeNet_cifar10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjo1QxLG7W7p",
        "colab_type": "code",
        "outputId": "affb9365-3e37-4753-9e77-216a18564253",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Importing ...')\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Importing ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiHvVp4lb98J",
        "colab_type": "text"
      },
      "source": [
        "使用datasets 准备数据集，并且将训练集 验证机 以及 测试集准备好。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXxv-7te8J_T",
        "colab_type": "code",
        "outputId": "9d286671-b1df-4c0e-c646-1983b48549a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# 其实就是数据增强操作,在dataloader中使用transforms\n",
        "train_transforms = transforms.Compose(\n",
        "[\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomCrop(32,padding=3),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.49139968, 0.48215827, 0.44653124), (0.24703233, 0.24348505, 0.26158768))\n",
        "]\n",
        ")\n",
        "\n",
        "test_transforms = transforms.Compose(\n",
        "[\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.49139968, 0.48215827, 0.44653124), (0.24703233, 0.24348505, 0.26158768))\n",
        "]\n",
        ")\n",
        "\n",
        "train_data = datasets.CIFAR10('data',train=True,download=True,transform=train_transforms)\n",
        "test_data = datasets.CIFAR10('data',train=False,download=True,transform=test_transforms)\n",
        "\n",
        "n_train = int(len(train_data)*0.9)\n",
        "n_valid = len(train_data) - n_train\n",
        "\n",
        "train_data,valid_data = torch.utils.data.random_split(train_data,[n_train,n_valid])\n",
        "\n",
        "print('train_data num is',n_train,'|valid_data numm is ',n_valid,'|test_data numm is',len(test_data))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "train_data num is 45000 |valid_data numm is  5000 |test_data numm is 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j059Fbf64ikY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "outputId": "a5e7970b-8574-471b-8008-cb93b287136f"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "x = next(iter(train_data))\n",
        "\n",
        "def show(img):\n",
        "  img = img.numpy()\n",
        "  plt.imshow(np.transpose(img,(1,2,0)))\n",
        "  \n",
        "print(x[0].shape)\n",
        "grid = torchvision.utils.make_grid(x[0],nrow=10,padding=100)\n",
        "\n",
        "show(grid)\n",
        "show(x[0])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 32, 32])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8rosLagAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2F8Gcp8DgVS0",
        "colab_type": "text"
      },
      "source": [
        "参数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxXPVdjR-LTF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "train_data_it = data.DataLoader(train_data, shuffle=True, batch_size = BATCH_SIZE)\n",
        "valid_data_it = data.DataLoader(valid_data, batch_size = BATCH_SIZE)\n",
        "test_data_it = data.DataLoader(test_data, batch_size = BATCH_SIZE)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXR6YL9dtLeR",
        "colab_type": "text"
      },
      "source": [
        "定义Model LeNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEypZ742gj5L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LeNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LeNet,self).__init__()\n",
        "    self.conv1 = nn.Conv2d(3,6,5)\n",
        "    self.conv2 = nn.Conv2d(6,16,5)\n",
        "    self.fc1 = nn.Linear(5*5*16 , 120)\n",
        "    self.fc2 = nn.Linear(120 , 84)\n",
        "    self.fc3 = nn.Linear(84 , 10)\n",
        "   \n",
        "  def forward(self,x):\n",
        "    x = F.max_pool2d(F.relu(self.conv1(x)) , 2)\n",
        "    x = F.max_pool2d(F.relu(self.conv2(x)) , 2)\n",
        "    x = x.view(x.shape[0],-1)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9V0FfSjCtK1T",
        "colab_type": "code",
        "outputId": "f619e822-9ad5-4455-f6da-88d223750784",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "model = LeNet().to(device)\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "print(model)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n",
            "LeNet(\n",
            "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AP8suNIuZKN",
        "colab_type": "text"
      },
      "source": [
        "计算准确率"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToE_0I2AuUMF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy_cal(pred, y):\n",
        "  # tensor.max选取 tensor中的最大值 \n",
        "  # max(1)将 最大值的 index 作为结果输出\n",
        "  prediction = pred.max(1)[1]\n",
        "  correct = prediction.eq(y.view_as(prediction)).sum()\n",
        "  acc = correct.float() / prediction.shape[0]\n",
        "  return acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfHSniaaxB94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, device , data , optimizer , loss_func):\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "  \n",
        "  model.train()\n",
        "  \n",
        "  for (x,y) in data:\n",
        "    \n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    pred = model(x)\n",
        "    loss = loss_func(pred, y)\n",
        "    acc = accuracy_cal(pred,y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    # item()将单值tensor转换成标量\n",
        "    epoch_loss += loss.item()\n",
        "    epoch_acc += acc.item()\n",
        "  return epoch_loss / len(data), epoch_acc / len(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "milidOP-yLl-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(model,device,data,loss_func):\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "  model.eval()\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    for (x,y) in data:\n",
        "      x = x.to(device)\n",
        "      y = y.to(device)\n",
        "      \n",
        "      pred = model(x)\n",
        "      loss = loss_func(pred,y)\n",
        "      acc = accuracy_cal(pred,y)\n",
        "      \n",
        "      epoch_loss += loss.item()\n",
        "      epoch_acc += acc.item()\n",
        "  return epoch_loss / len(data), epoch_acc / len(data)\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHC2tRSmzYBm",
        "colab_type": "code",
        "outputId": "90ed222a-639e-4d31-f026-905e78fe3fba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "EPOCH = 50\n",
        "SAVE_DIR = 'models'\n",
        "MODEL_SAVE_DIR = os.path.join(SAVE_DIR,'LeNet_cifar10.pt')\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "\n",
        "if not os.path.isdir(f'{SAVE_DIR}'):\n",
        "  os.makedirs(f'{SAVE_DIR}')\n",
        "  \n",
        "for epoch in range(EPOCH):\n",
        "  print('Epoch is ',epoch)\n",
        "  train_loss , train_acc = train(model,device,train_data_it,optimizer,loss_func)\n",
        "  valid_loss , valid_acc = test(model,device,valid_data_it,loss_func)\n",
        "  \n",
        "  if valid_loss < best_valid_loss:\n",
        "    best_valid_loss = valid_loss\n",
        "    torch.save(model.state_dict(),MODEL_SAVE_DIR)\n",
        "  print('|EPOCH ',epoch,'|Train Loss is ',train_loss,'|Train Acc is ',train_acc,'|Valid Loss is ',valid_loss,'|Valid acc is ',valid_acc)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch is  0\n",
            "|EPOCH  0 |Train Loss is  1.1130904591726987 |Train Acc is  0.6037819602272727 |Valid Loss is  1.140095768095572 |Valid acc is  0.6042325949367089\n",
            "Epoch is  1\n",
            "|EPOCH  1 |Train Loss is  1.0980003606528044 |Train Acc is  0.6075328480113636 |Valid Loss is  1.1139715879778318 |Valid acc is  0.6089794303797469\n",
            "Epoch is  2\n",
            "|EPOCH  2 |Train Loss is  1.08692022675479 |Train Acc is  0.612060546875 |Valid Loss is  1.08654876524889 |Valid acc is  0.6214398734177216\n",
            "Epoch is  3\n",
            "|EPOCH  3 |Train Loss is  1.0775537708435545 |Train Acc is  0.6170321377840909 |Valid Loss is  1.1003138355061979 |Valid acc is  0.617879746835443\n",
            "Epoch is  4\n",
            "|EPOCH  4 |Train Loss is  1.062996600754559 |Train Acc is  0.6226029829545454 |Valid Loss is  1.1189618284189249 |Valid acc is  0.6137262658227848\n",
            "Epoch is  5\n",
            "|EPOCH  5 |Train Loss is  1.0485334133052013 |Train Acc is  0.6276411576704546 |Valid Loss is  1.054457101640822 |Valid acc is  0.6261867088607594\n",
            "Epoch is  6\n",
            "|EPOCH  6 |Train Loss is  1.0411298214881257 |Train Acc is  0.6300159801136364 |Valid Loss is  1.10267622033252 |Valid acc is  0.6157041139240507\n",
            "Epoch is  7\n",
            "|EPOCH  7 |Train Loss is  1.0410616803406314 |Train Acc is  0.6290616122159091 |Valid Loss is  1.064484767521484 |Valid acc is  0.6263844936708861\n",
            "Epoch is  8\n",
            "|EPOCH  8 |Train Loss is  1.0235139065506784 |Train Acc is  0.6385609019886364 |Valid Loss is  1.0689958183071282 |Valid acc is  0.6277689873417721\n",
            "Epoch is  9\n",
            "|EPOCH  9 |Train Loss is  1.017473111606457 |Train Acc is  0.6371404474431818 |Valid Loss is  1.0394253745863709 |Valid acc is  0.6319224683544303\n",
            "Epoch is  10\n",
            "|EPOCH  10 |Train Loss is  1.0141793712126939 |Train Acc is  0.6403142755681818 |Valid Loss is  1.0293747118756742 |Valid acc is  0.6469541139240507\n",
            "Epoch is  11\n",
            "|EPOCH  11 |Train Loss is  1.0087322542782535 |Train Acc is  0.6418900923295454 |Valid Loss is  1.0306692251676246 |Valid acc is  0.6376582278481012\n",
            "Epoch is  12\n",
            "|EPOCH  12 |Train Loss is  1.0030172566290607 |Train Acc is  0.6450417258522727 |Valid Loss is  1.0251859600030924 |Valid acc is  0.6433939873417721\n",
            "Epoch is  13\n",
            "|EPOCH  13 |Train Loss is  0.9970433318733491 |Train Acc is  0.6479270241477273 |Valid Loss is  1.0593924967548516 |Valid acc is  0.6269778481012658\n",
            "Epoch is  14\n",
            "|EPOCH  14 |Train Loss is  0.9989752794023264 |Train Acc is  0.6445090553977273 |Valid Loss is  1.0308786034584045 |Valid acc is  0.6333069620253164\n",
            "Epoch is  15\n",
            "|EPOCH  15 |Train Loss is  0.9833642863245173 |Train Acc is  0.6519220525568182 |Valid Loss is  1.115144911446149 |Valid acc is  0.6099683544303798\n",
            "Epoch is  16\n",
            "|EPOCH  16 |Train Loss is  0.9742600817910649 |Train Acc is  0.6546963778409091 |Valid Loss is  1.0292211944543863 |Valid acc is  0.6366693037974683\n",
            "Epoch is  17\n",
            "|EPOCH  17 |Train Loss is  0.9798249835995111 |Train Acc is  0.6523881392045454 |Valid Loss is  1.0247997777371467 |Valid acc is  0.6374604430379747\n",
            "Epoch is  18\n",
            "|EPOCH  18 |Train Loss is  0.9792955227365548 |Train Acc is  0.6515003551136364 |Valid Loss is  1.033971736702738 |Valid acc is  0.6414161392405063\n",
            "Epoch is  19\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-65908c40fe8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch is '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m   \u001b[0mtrain_loss\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_data_it\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m   \u001b[0mvalid_loss\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_data_it\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-a37461e8bd97>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, data, optimizer, loss_func)\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    986\u001b[0m         \u001b[0mangle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdegrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 988\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mangle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcenter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    990\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mrotate\u001b[0;34m(img, angle, resample, expand, center)\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'img should be PIL Image. Got {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mangle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcenter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1RR2mdt1UdU",
        "colab_type": "code",
        "outputId": "2664418f-4938-498f-9c98-8ba9fbd7b245",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.load_state_dict(torch.load(MODEL_SAVE_DIR))\n",
        "test_loss, test_acc = test(model,device,test_data_it,loss_func)\n",
        "print('Test Loss is ',test_loss,'|Test ACC is ',test_acc)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss is  1.030051958788732 |Test ACC is  0.6329617834394905\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8__wE9hDcPp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}